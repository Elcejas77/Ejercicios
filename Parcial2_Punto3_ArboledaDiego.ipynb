{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elcejas77/Ejercicios/blob/main/Parcial2_Punto3_ArboledaDiego.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARCIAL 2-PUNTO 3\n",
        "DIEGO ALEJANDRO ARBOLEDA CUERO\n",
        "\n",
        "CC:1087834596\n",
        "\n",
        "Para la solucion de este punto utilizaremos como base el codigo guia del parcial,donde ya esta ingresada toda la informacion necesaria."
      ],
      "metadata": {
        "id": "Ym57Znzy-eTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case Western Reserve Experiments\n",
        "\n",
        "\n",
        "Sea la base de datos para el monitoreo de condición (fallos) en rodamientos a partir del análisis de vibraciones descrita en [Case Western Reserve Experiments](https://engineering.case.edu/bearingdatacenter). Las señales fueron adquiridas para las siguientes condiciones (clases): i) Normal bearing (Nor), fault in the internal train (IR1), fault in the external train (IR2), and fault in the rolling element-ball (BE). Además, los fallos se generaron para tres niveles de severidad (profundidad): 0.007′′, 0.014′′, and 0.021′′ y tres velocidades de operación (1730, 1750, 1772, and 1797 [rpm]). Los datos fueron adquiridos a 12 kHz. Por consiguiente, se tienen los siguientes parámetros de estudio: $F_s=12k$ [Hz] cantidad de puntos en el tiempo $4096$ y cantidad de clases $C = 10$.\n",
        "\n",
        "Grafique la señal promedio de cada fallo en el tiempo y en la frecuencia.\n",
        "\n",
        "Utilizando la transformada rápida de Fourier diseñe y construya un detector fallos en rodamientos a partir de señales de vibración y sus etiquetas en los arreglos Xtrain y Ytrain (ver cuaderno de apoyo). Genere las predicciones de fallos para el arreglo Xtest."
      ],
      "metadata": {
        "id": "RdP1id0o3Ry0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lKHA47I1-UE"
      },
      "outputs": [],
      "source": [
        "#data downloaded for google drive\n",
        "FILEID = \"1IC11LrPCZIo_Am5eXP2p2tDAlrGTlPjn\"\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O datos.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip -o datos.zip\n",
        "!dir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#librerias\n",
        "import scipy.io as sio\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "import warnings\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import matplotlib\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#cargar datos\n",
        "path_ = 'CaractCE.mat'#Case Western Database\n",
        "dicX = sio.loadmat(path_)"
      ],
      "metadata": {
        "id": "FeQgT1n13EZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = dicX['F'] #datos en el tiempo\n",
        "Fs = 12000 #frecuencia de muestreo\n",
        "Tl = Xt.shape[1]/Fs #tamaño del segmento\n",
        "print('Xt shape:',Xt.shape)\n",
        "print('tiempo [s]', Tl)\n",
        "\n",
        "Y = dicX['E']\n",
        "Ytrue = Y[:,2] #clases fallos en los rodamientos\n",
        "\n",
        "labels_ = ['NOR','IR1_0.007´´','IR1_0.014´´','IR1_0.021´´',\n",
        "           'IR2_0.007´´','IR2_0.014´´','IR2_0.021´´',\n",
        "           'BE_0.007´´','BE_0.014´´','BE_0.021´´'\n",
        "           ] #nombres de las clases"
      ],
      "metadata": {
        "id": "1yN9Ox193IbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Ytrue.shape) #etique membresia de los datos 10 posibles valores\n",
        "print(np.unique(Ytrue))"
      ],
      "metadata": {
        "id": "HbuSRvEN3K0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#partir datos para train y test\n",
        "Xtrain, Xtest, Ytrain, _ = train_test_split(Xt, Ytrue, test_size=0.3)\n",
        "\n",
        "print(f\"Xtrain shape {Xtrain.shape}, Ytrain shape {Ytrain.shape }Xtest shape {Xtest.shape} \")"
      ],
      "metadata": {
        "id": "x3TqREMU3LHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calcular espectro de Fourier Xtrain\n",
        "vf = np.fft.rfftfreq(Xtrain.shape[1],1/Fs) #freq vector\n",
        "Xw = (abs(np.fft.rfft(Xtrain))) # FFT\n",
        "Xw.shape"
      ],
      "metadata": {
        "id": "r0VZN69T3auJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#graficar espectro para clases representativas\n",
        "sca_ = MinMaxScaler()\n",
        "Xw_ = sca_.fit_transform(Xw.T).T\n",
        "#red = TSNE(perplexity = 15,n_components=2,random_state=123,learning_rate='auto',init='pca')\n",
        "red = PCA(n_components=2)\n",
        "Z = red.fit_transform(Xw_)\n",
        "\n",
        "plt.scatter(Z[:,0],Z[:,1],c=Ytrain, label='Xtrain')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fphITOjOYW2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tenemos que tener en cuenta que necesitamos una lista para almacenar los promedios de cada clase definida anteriormente"
      ],
      "metadata": {
        "id": "tfMrnchaJcTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "p_ti = []\n",
        "\n",
        "# Calcular el promedio en el tiempo para cada clase\n",
        "for clase in np.unique(Ytrue):\n",
        "    p_cl = np.mean(Xtrain[Ytrain == clase], axis=0)\n",
        "    p_ti.append(p_cl)\n",
        "\n"
      ],
      "metadata": {
        "id": "JDu-13x65l32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "graficamos el pomedio en el tiempo de cada clase"
      ],
      "metadata": {
        "id": "zkJ3Kt1BKAR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "for i, p_cl in enumerate(p_ti):\n",
        "    plt.plot(p_cl, label=labels_[i])\n",
        "\n",
        "\n",
        "plt.xlabel(\"Muestras en el tiempo\")\n",
        "plt.ylabel(\"Amplitud\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RGJSu3IEJ9U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ya con la informacion obtenida dela base de datos podemos calcular lo9s promedios en frecuencia para cada clase y asi empezar a darle forma a la solucion del ejercicio"
      ],
      "metadata": {
        "id": "Xyv5ta-0Kpyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pr_f =promedio en frecuencia\n",
        "#pr_espec=promedio espectro\n",
        "\n",
        "pr_f = []  #vector donde estaran los valores del promedio en frecuencia\n",
        "\n",
        "for clase in np.unique(Ytrain):\n",
        "    espectros = Xw[Ytrain == clase]\n",
        "    pr_espec = np.mean(espectros, axis=0)\n",
        "    pr_f.append(pr_espec)\n"
      ],
      "metadata": {
        "id": "vjdUMjuR5nY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se procede a graficar el promedio en frecuencia de cada clase obtenida en el codigo anterior"
      ],
      "metadata": {
        "id": "HT304upTLbXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "for i, promedio_espectro in enumerate(pr_f):\n",
        "    plt.plot(vf, promedio_espectro, label=labels_[i])\n",
        "\n",
        "plt.title(\"Promedio en la frecuencia de cada clase de fallo\")\n",
        "plt.xlabel(\"Frecuencia (Hz)\")\n",
        "plt.ylabel(\"Amplitud\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pdCBW-1kK50c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculamos la transformada para xwtest y le pedimos que nos devuelva la forma del vector"
      ],
      "metadata": {
        "id": "Dfrf5uk0MRjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vftest = np.fft.rfftfreq(Xtest.shape[1],1/Fs) #freq vector\n",
        "Xwtest = (abs(np.fft.rfft(Xtest))) # FFT\n",
        "Xwtest.shape"
      ],
      "metadata": {
        "id": "B-svVSitepc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalizamos el vector de amplitudes de componentes de frecuencia. y  el vector Xwnormal contiene ahora las amplitudes de las componentes de frecuencia de la señal Xw normalizadas de acuerdo con su media y desviación estándar"
      ],
      "metadata": {
        "id": "ZfVIsVm8Mta9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#desviacion tarin=desvia_tra\n",
        "mediatrain=np.mean(Xw)\n",
        "desvia_tra=np.std(Xw)\n",
        "Xwnormal = (Xw-mediatrain)/desvia_tra\n",
        "Xwnormal"
      ],
      "metadata": {
        "id": "bWK7SbNwfME-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que en el caso anterior normalizamos Xwest ,y el vector Xwnormal1 contiene ahora las amplitudes de las componentes de frecuencia de la señal Xwtest normalizadas de acuerdo con su media y desviación estándar"
      ],
      "metadata": {
        "id": "biEfh4aQNHnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#desviaciontest1=desvia1\n",
        "mediatest=np.mean(Xwtest)\n",
        "desvia1=np.std(Xwtest)\n",
        "Xwnormal1 = (Xwtest-mediatest)/desvia1\n",
        "Xwnormal1"
      ],
      "metadata": {
        "id": "MA4Vd5defy3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "y para finiquitar usamos  la función cdist de scipy.spatial.distance para calcular distancias entre dos conjuntos de puntos y asignar etiquetas basadas en la distancia mínima.y realizar una asignación de etiquetas a los elementos del conjunto de prueba Xtest en función de la distancia mínima a los elementos del conjunto de entrenamiento Xw, utilizando las etiquetas correspondientes en Ytrain."
      ],
      "metadata": {
        "id": "6jQ_VU7sNvRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "contar= []\n",
        "for i in range(len(Xtest)):\n",
        "  p=cdist(Xwtest,Xw)\n",
        "  contar.append(Ytrain[np.argmin(p[i,])])\n"
      ],
      "metadata": {
        "id": "-idVJ2UAgN3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y graficamos cuantos errores tenemos de cada clase"
      ],
      "metadata": {
        "id": "-KsBTFpufX8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lista1=labels_\n",
        "lista2=[contar.count(1),contar.count(2),contar.count(3),contar.count(4),contar.count(5),contar.count(6),contar.count(7),contar.count(8),contar.count(9),contar.count(10)]\n",
        "y_pos = np.arange(len(lista2))\n",
        "plt.barh(y_pos, lista2, align='center', alpha=0.5)\n",
        "plt.yticks(y_pos, lista1)\n",
        "plt.xlabel('Numero de errores')\n",
        "\n",
        "plt.title('Grafico de numero de errores de cada tipo')\n",
        "plt.savefig('barras_horizontal.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G-kmU1_zeqPZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}